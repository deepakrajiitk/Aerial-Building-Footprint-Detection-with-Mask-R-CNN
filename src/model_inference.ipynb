{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Defining Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, message='`np.bool` is a deprecated alias')\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import fiona \n",
    "from shapely.geometry import shape, box\n",
    "import rasterio\n",
    "from PIL import Image, ImageDraw\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import tensorflow as tf\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from patchify import patchify, unpatchify\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "import geopandas as gpd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"mrcnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, \"Dataset\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = \"../models/mask_rcnn_coco.h5\"\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig(Config):\n",
    "    NAME = \"BuildingDetection\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 4\n",
    "    STEPS_PER_EPOCH = 2770\n",
    "    VALIDATION_STEPS = 234\n",
    "    BACKBONE = \"resnet101\"\n",
    "    NUM_CLASSES = 2 #bulding and background\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "    IMAGE_MIN_DIM = 1024\n",
    "\n",
    "    TRAIN_ROIS_PER_IMAGE = 50\n",
    "    \n",
    "    MAX_GT_INSTANCES = 50\n",
    "    LOSS_WEIGHTS = {\n",
    "        \"rpn_class_loss\": 2.,\n",
    "        \"rpn_bbox_loss\": 1.,\n",
    "        \"mrcnn_class_loss\": 1.,\n",
    "        \"mrcnn_bbox_loss\": 1.,\n",
    "        \"mrcnn_mask_loss\": 10.\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(TrainingConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inference = modellib.MaskRCNN(mode=\"inference\", config=inference_config, model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "model_path = os.path.join(MODEL_DIR, \"../logs/buildingdetection20230801T1248/mask_rcnn_buildingdetection_0041.h5\")\n",
    "# model_path = model_inference.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model_inference.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference on multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image_path, patch_size, step):\n",
    "    \"\"\"\n",
    "    Extract patches from an image and return the patches along with a padded image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        patch_size (tuple): Size of each patch in (height, width) format.\n",
    "        step (int): Step size for patch extraction.\n",
    "\n",
    "    Returns:\n",
    "        patches (numpy.ndarray): Extracted patches.\n",
    "        padded_image (numpy.ndarray): Padded image to fit patches evenly.\n",
    "    \"\"\"\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Convert the PIL image to a NumPy array\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Calculate the number of patches in each dimension\n",
    "    num_patches_y = (image_np.shape[0] + patch_size[0] - 1) // patch_size[0]\n",
    "    num_patches_x = (image_np.shape[1] + patch_size[1] - 1) // patch_size[1]\n",
    "    \n",
    "    # Calculate the required padding to fit the patches evenly\n",
    "    pad_y = num_patches_y * patch_size[0] - image_np.shape[0]\n",
    "    pad_x = num_patches_x * patch_size[1] - image_np.shape[1]\n",
    "    \n",
    "    # Pad the image\n",
    "    \n",
    "    if(len(image_np.shape)<3):\n",
    "        print(\"RGB channels missing in\", image_path)\n",
    "        return [], []\n",
    "    else:\n",
    "        padded_image = np.pad(image_np, ((0, pad_y), (0, pad_x), (0, 0)), mode='constant')\n",
    "    \n",
    "    # Divide the padded image into patches\n",
    "    patches = patchify(padded_image, patch_size, step=step)\n",
    "    \n",
    "    return patches, padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_mask_on_edge(mask, edge_percentage, mask_percentage):\n",
    "    \"\"\"\n",
    "    Check if a mask is present on the edges of an image.\n",
    "\n",
    "    Args:\n",
    "        mask (numpy.ndarray): Binary mask.\n",
    "        edge_percentage (float): Percentage of edges to consider (0 to 1).\n",
    "        mask_percentage (float): Minimum percentage of mask pixels on an edge (0 to 1).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if mask is on any edge, False otherwise.\n",
    "    \"\"\"\n",
    "    height, width = mask.shape\n",
    "    total_mask_area = np.sum(mask)\n",
    "    edge_pixels = int(min(height, width) * edge_percentage)\n",
    "\n",
    "    # Check top edge\n",
    "    if np.sum(mask[:edge_pixels, :]) >= mask_percentage * total_mask_area:\n",
    "        return True\n",
    "    \n",
    "    # Check bottom edge\n",
    "    if np.sum(mask[-edge_pixels:, :]) >= mask_percentage * total_mask_area:\n",
    "        return True\n",
    "    \n",
    "    # Check left edge\n",
    "    if np.sum(mask[:, :edge_pixels]) >= mask_percentage * total_mask_area:\n",
    "        return True\n",
    "    \n",
    "    # Check right edge\n",
    "    if np.sum(mask[:, -edge_pixels:]) >= mask_percentage * total_mask_area:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_polygons(r, x, y, eps = 0.02):\n",
    "    \"\"\"\n",
    "    Find polygons from instance segmentation results.\n",
    "\n",
    "    Args:\n",
    "        r (dict): Result dictionary containing masks and bounding boxes.\n",
    "        x (int): X-coordinate shift.\n",
    "        y (int): Y-coordinate shift.\n",
    "        eps (float, optional): Epsilon value for polygon approximation. \n",
    "            Controls the precision of the approximation. Default is 0.02.\n",
    "\n",
    "    Returns:\n",
    "        polygons (list): List of Shapely Polygon objects representing objects.\n",
    "    \"\"\"\n",
    "    masks = r['masks']\n",
    "    bboxes = r['rois']\n",
    "    n = bboxes.shape[0]\n",
    "    polygons = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        mask = masks[:, :, i]\n",
    "        mask = mask.astype(np.uint8)\n",
    "\n",
    "        # Ignore incomplete building masks on sides of images\n",
    "        if is_mask_on_edge(mask, 0.2, 0.5):\n",
    "            continue\n",
    "        \n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        for contour in contours:\n",
    "            epsilon = eps * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, closed=False)\n",
    "            \n",
    "            shifted_polygon = np.array(approx) + np.array([x, y])\n",
    "            \n",
    "            # Convert the shifted_polygon to a GeoDataFrame Polygon\n",
    "            poly_coords = [(point[0][0], point[0][1]) for point in shifted_polygon]\n",
    "            if len(poly_coords) >= 4:\n",
    "                polygon = Polygon(poly_coords)\n",
    "                polygons.append(polygon)\n",
    "            \n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_patch_overlap_adjustment(polygons, prev_polygons, overlap_threshold):\n",
    "    adjusted_polygons = []\n",
    "    for polygon in polygons:\n",
    "        if polygon.is_valid:\n",
    "            overlap = False  # Flag to track if there's any overlap with previous polygons\n",
    "            for prev_poly in prev_polygons:\n",
    "                if prev_poly.is_valid and polygon.intersection(prev_poly).area >= overlap_threshold * polygon.area:\n",
    "                    overlap = True\n",
    "                    break  # No need to check further, there's an overlap\n",
    "            if not overlap:\n",
    "                adjusted_polygons.append(polygon)\n",
    "    return adjusted_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_patches_with_overlap_adjustment(image_path, patches, model_inference, step, overlap_threshold, output_shp_path):\n",
    "    # Open the input image\n",
    "    image = Image.open(image_path)\n",
    "    image_width, image_height = image.size\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Extract CRS from the TIFF image\n",
    "    with rasterio.open(image_path) as src:\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "    \n",
    "    # Initialize a 2D list to store polygons for each patch\n",
    "    patch_polygons = [[[] for _ in range(patches.shape[1])] for _ in range(patches.shape[0])]\n",
    "    \n",
    "    # Create a list to store all polygons for the shapefile\n",
    "    all_polygons = []\n",
    "\n",
    "    for i in range(patches.shape[0]):\n",
    "        for j in range(patches.shape[1]):\n",
    "            # Extract the current patch\n",
    "            patch = patches[i, j, 0, :, :, :3]\n",
    "            \n",
    "            # Perform model inference to detect objects in the patch\n",
    "            r = model_inference.detect([patch])[0]\n",
    "            \n",
    "            # Find polygons from the detection results and adjust for overlap\n",
    "            polygons = find_polygons(r, j * step, i * step)\n",
    "            \n",
    "            # Apply overlap adjustment with the previous row\n",
    "            if i > 0:\n",
    "                prev_row_polygons = patch_polygons[i - 1][j]\n",
    "                polygons = apply_patch_overlap_adjustment(polygons, prev_row_polygons, overlap_threshold)\n",
    "            \n",
    "            # Apply overlap adjustment with the previous column\n",
    "            if j > 0:\n",
    "                prev_col_polygons = patch_polygons[i][j - 1]\n",
    "                polygons = apply_patch_overlap_adjustment(polygons, prev_col_polygons, overlap_threshold)\n",
    "            \n",
    "            # Apply overlap adjustment with the diagonal patch (top-left)\n",
    "            if i > 0 and j > 0:\n",
    "                prev_diag_polygons = patch_polygons[i - 1][j - 1]\n",
    "                polygons = apply_patch_overlap_adjustment(polygons, prev_diag_polygons, overlap_threshold)\n",
    "            \n",
    "            # Apply overlap adjustment with the diagonal patch (top-right)\n",
    "            if i > 0 and j < patches.shape[1]-1:\n",
    "                prev_diag_polygons = patch_polygons[i - 1][j + 1]\n",
    "                polygons = apply_patch_overlap_adjustment(polygons, prev_diag_polygons, overlap_threshold)\n",
    "            \n",
    "            # Store the adjusted polygons in the 2D list\n",
    "            patch_polygons[i][j] = polygons\n",
    "\n",
    "            # Append the adjusted polygons to the list of all polygons\n",
    "            all_polygons.extend(polygons)\n",
    "            \n",
    "            # Print a message to indicate patch processing completion\n",
    "            print(f\"Patch {i},{j} completed\")\n",
    "\n",
    "    # Transform polygon coordinates from pixel to the TIFF file's coordinate system\n",
    "    transformed_polygons = []\n",
    "    for polygon in all_polygons:\n",
    "        points = []\n",
    "        for point in polygon.exterior.coords:\n",
    "            x, y = point\n",
    "            lon, lat = transform * (x + 0.5, y + 0.5)\n",
    "            points.append((lon, lat))\n",
    "        transformed_polygons.append(Polygon(points))\n",
    "\n",
    "    # Create a GeoDataFrame from the list of transformed polygons\n",
    "    geometry = gpd.GeoSeries(transformed_polygons)\n",
    "    print(len(all_polygons))\n",
    "    gdf = gpd.GeoDataFrame(geometry=geometry, crs=crs)  # You might need to adjust the CRS\n",
    "    \n",
    "    # Save the GeoDataFrame as a shapefile\n",
    "    gdf.to_file(output_shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_threshold = 0.5  # Adjust this threshold as needed\n",
    "patch_size = (1024, 1024, 3)  # Adjust this to the desired patch size and channel count\n",
    "step = 512\n",
    "input_folder = \"../Dataset/Orthos_DSMs_Shapefiles/\"\n",
    "output_folder = \"../results2\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Iterate over folders in the input directory\n",
    "for tif_folder in os.listdir(input_folder)[:1]:\n",
    "    geotiff_folder = os.path.join(input_folder, tif_folder)\n",
    "    geotiff_folder = os.path.join(geotiff_folder, \"GeoTiff\")\n",
    "    curr_output_folder = os.path.join(output_folder, tif_folder)\n",
    "    \n",
    "    # Create output folder if it doesn't exist\n",
    "    if not os.path.exists(curr_output_folder):\n",
    "        os.makedirs(curr_output_folder)\n",
    "\n",
    "    # Iterate over files in the GeoTiff folder\n",
    "    for filename in os.listdir(geotiff_folder):    \n",
    "        if filename.endswith(\".tif\"):\n",
    "            input_path = os.path.join(geotiff_folder, filename)\n",
    "            print(\"Working on\", input_path)\n",
    "\n",
    "            inside_folder = os.path.join(curr_output_folder, f\"{filename[:-4]}\")\n",
    "            \n",
    "            # Create a subfolder for each input file\n",
    "            if not os.path.exists(inside_folder):\n",
    "                os.makedirs(inside_folder)\n",
    "\n",
    "            # if len(os.listdir(inside_folder))==0:\n",
    "            #     os.rmdir(inside_folder)\n",
    "            #     print(\"deleting\", inside_folder)\n",
    "            #     continue\n",
    " \n",
    "            # output_path = os.path.join(inside_folder, f\"output_{filename[:-4]}\"+\"_palette.shp\")\n",
    "            # print(\"Output path:\", output_path)\n",
    "\n",
    "            output_path = os.path.join(inside_folder, f\"output_{filename[:-4]}\"+\".shp\")\n",
    "            print(\"Output path:\", output_path)\n",
    "            \n",
    "            # Skip processing if the output file already exists\n",
    "            if os.path.exists(output_path):\n",
    "                continue\n",
    "            \n",
    "            # Extract patches from the input image\n",
    "            patches, padded_image = extract_patches(input_path, patch_size, step)\\\n",
    "            \n",
    "            # Process patches with overlap adjustment and save results as a shapefile\n",
    "            if(len(patches)):\n",
    "                process_patches_with_overlap_adjustment(input_path, patches, model_inference, step, overlap_threshold, output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference on single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlap_threshold = 0.5  # Adjust this threshold as needed\n",
    "# image_path = \"../Dataset/Orthos_DSMs_Shapefiles/Dharmavaram_Mudigubba_NAGAREDDYPALLI_2621400/GeoTiff2/Nagareddypalli_Ortho_H1.tif\"  # Path to your test image\n",
    "# patch_size = (1024, 1024, 3)  # Adjust this to the desired patch size and channel count\n",
    "# step = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patches, padded_image = extract_patches(image_path, patch_size, step)\n",
    "# print(f\"Number of patches: {patches.shape[0] * patches.shape[1]}\")\n",
    "# print(f\"Shape of a single patch: {patches[0, 0, 0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_patches(patches, \"../Dataset/patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_shp_path = \"../shp_files/output_shp.shp\"\n",
    "# process_patches_with_overlap_adjustment(image_path, patches, model_inference, step, overlap_threshold, output_shp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrcnn_kernel",
   "language": "python",
   "name": "mrcnn_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
